{"cells":[{"cell_type":"markdown","metadata":{"id":"2sF-53bMFKN3"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1y46sktFFP97"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Bei0R7AFKN4"},"outputs":[],"source":["%matplotlib inline\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import r2_score, mean_absolute_error\n","from sklearn.svm import SVR\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import KFold\n","from sklearn.linear_model import ElasticNet\n","from sklearn.model_selection import RandomizedSearchCV\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"BJVqINZwFKN6"},"source":["## Read dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pHuUtDf_FKN7"},"outputs":[],"source":["data = pd.read_csv(\"/content/drive/MyDrive/Dataset/Link_Level/DS_SMF_LinkLevel_1e4_uniform_211204.csv\")\n","data.head()"]},{"cell_type":"markdown","metadata":{"id":"fzod1dJAFKN-"},"source":["## Data Analysis"]},{"cell_type":"markdown","metadata":{"id":"rKliN8_pFKOB"},"source":["## Data Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n87OhZZcfcvV"},"outputs":[],"source":["fig = data.hist(bins=50, figsize=(50, 30), xlabelsize=10, ylabelsize=10)\n","[x.title.set_size(32) for x in fig.ravel()]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cgdHBrVahUDI"},"outputs":[],"source":["plt.figure()\n","fig,ax = plt.subplots(figsize=(30,15))\n","sns.boxplot(x = 'Lspan(KM)', y = 'GSNRSpan(dB)',  data = data,ax=ax)\n","plt.title('Lspan(KM) vs GSNRSpan(dB)', fontdict = {'fontsize' : 30})\n","plt.xlabel('Lspan(KM)', fontsize=18)\n","plt.ylabel('GSNRSpan(dB)', fontsize=16)\n","ticks = plt.setp(ax.get_xticklabels(),rotation=90)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g8wmlBjYFKOE"},"outputs":[],"source":["clean_data = data   # data set doesn't need cleaning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hZyGJ9r8FKOI"},"outputs":[],"source":["X = clean_data.iloc[:,:-1]\n","y = clean_data.iloc[:,-1]"]},{"cell_type":"markdown","metadata":{"id":"iengTdvyFKOI"},"source":["## Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZKpkqBgiFKOJ"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"]},{"cell_type":"markdown","metadata":{"id":"uzxwTxCNFKON"},"source":["## Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cun85TVgFKON"},"outputs":[],"source":["numerical_columns = list(X_train)\n","categorical_columns = [\"Rs(GBu)\"] # based on trial and error and also histograms this column can be considered as a categorical feature"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0doaHeV-FKON"},"outputs":[],"source":["# creating a pipieline for numerical features which normalizes all the \n","# given features as well as filling some missing data (which is not really necessary here)\n","numerical_pipeline = Pipeline([                     \n","        ('data_filler', SimpleImputer(strategy=\"median\")),\n","        ('std_scaler', StandardScaler()),\n","    ])\n","# implementing all the changes by 'fit_transform'\n","X_train_numerical = numerical_pipeline.fit_transform(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gDqZXqC-FKON"},"outputs":[],"source":["# the same is done for categorical data by ignoring the unknown elements while categorizing\n","pipeline = ColumnTransformer([\n","        (\"numerical\", numerical_pipeline, numerical_columns),\n","        (\"categorical\", OneHotEncoder(handle_unknown = \"ignore\"), categorical_columns),\n","    ])"]},{"cell_type":"markdown","metadata":{"id":"QEbuVLZIFKOO"},"source":["## Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1N-zt3PIFKOO"},"outputs":[],"source":["# defining a function to print the evaluation metrics to avoid any duplicated line of code in the nest parts\n","def rmse_r2_mae(model,y,y_predict):    \n","    rmse = (np.sqrt(mean_squared_error(y, y_predict)))\n","    r2 = r2_score(y, y_predict)\n","    mae = mean_absolute_error(y,y_predict)\n","    print('RMSE is {}'.format(rmse))\n","    print('R2 score is {}'.format(r2))\n","    print('MAE score is {}'.format(mae))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JnsxZVipFKOO"},"outputs":[],"source":["# the same an previous part but with different inputs when predicted data is not accessible\n","def score_rmse_r2_mae(model,X,y):    \n","    rmse = cross_val_score(model, X, y, cv=5, scoring='neg_root_mean_squared_error').mean()\n","    r2 = cross_val_score(model, X, y, cv=5, scoring='r2').mean()\n","    mae = cross_val_score(model, X, y, cv=5, scoring='mean_absolute_error').mean()\n","    print('RMSE is {}'.format(rmse))\n","    print('R2 score is {}'.format(r2))\n","    print('MAE score is {}'.format(mae))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z3IlnK-8FKOP"},"outputs":[],"source":["def get_score_predict(model,X_train,y_train,X_test,y_test):\n","    print(\"\\nThe model performance for training set\")\n","    print(\"--------------------------------------\")\n","    score_rmse_r2_mae(model,X_train,y_train)\n","    print(\"\\nThe model performance for validation set\")\n","    print(\"--------------------------------------\")\n","    score_rmse_r2_mae(model,X_test,y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8dDQ_vvtFKOP"},"outputs":[],"source":["def test_score(model,X,y):\n","    print(\"\\nThe model performance for testing set\")\n","    print(\"--------------------------------------\")\n","    score_rmse_r2_mae(model,X,y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tz8OyLRPFKOP"},"outputs":[],"source":["def get_model_grid_search(model, parameters, X, y, pipeline):\n","    \n","    X = pipeline.fit_transform(X)    \n","    # definng R2 as scoring method\n","    random_search = RandomizedSearchCV(model,\n","                            param_distributions=parameters,\n","                            scoring='r2',\n","                            verbose=1, n_jobs=-1,\n","                            n_iter=1000)\n","    \n","    grid_result = random_search.fit(X, y)\n","    \n","    print('Best R2: ', grid_result.best_score_)\n","    print('Best Params: ', grid_result.best_params_)  \n","  \n","    # definng MAE as scoring method\n","    random_search2 = RandomizedSearchCV(model,\n","                            param_distributions=parameters,\n","                            scoring='neg_mean_absolute_error',\n","                            verbose=1, n_jobs=-1,\n","                            n_iter=1000)\n","    \n","    grid_result2 = random_search2.fit(X, y)\n","    \n","    print('Best MAE: ', grid_result2.best_score_)\n","    print('Best Params: ', grid_result2.best_params_) \n","  \n","    # definng RMSE as scoring method\n","    random_search3 = RandomizedSearchCV(model,\n","                            param_distributions=parameters,\n","                            scoring='neg_root_mean_squared_error',\n","                            verbose=1, n_jobs=-1,\n","                            n_iter=1000)\n","    \n","    grid_result3 = random_search3.fit(X, y)\n","    \n","    print('Best RMSE: ', grid_result3.best_score_)\n","    print('Best Params: ', grid_result3.best_params_) \n","    \n","    return random_search.best_estimator_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"toLBVyoYFKOQ"},"outputs":[],"source":["def get_model_random_search(model, parameters, X, y, pipeline):\n","    \n","    X = pipeline.fit_transform(X)    \n","    clf = GridSearchCV(model, parameters, scoring='r2',cv=5,verbose=1, n_jobs=-1)\n","    grid_result = clf.fit(X, y)\n","      \n","    # definng R2 as scoring method\n","    print('Best R2: ', grid_result.best_score_)\n","    print('Best Params: ', grid_result.best_params_) \n","  \n","    # definng MAE as scoring method\n","    clf2 = GridSearchCV(model, parameters, scoring='neg_mean_absolute_error',cv=5,verbose=1, n_jobs=-1)\n","    grid_result2 = clf2.fit(X, y)\n","\n","    print('Best MAE: ', grid_result2.best_score_)\n","    print('Best Params: ', grid_result2.best_params_)\n","  \n","    # definng RMSE as scoring method\n","    clf3 = GridSearchCV(model, parameters, scoring='neg_root_mean_squared_error',cv=5,verbose=1, n_jobs=-1)\n","    grid_result3 = clf3.fit(X, y)\n","\n","    print('Best MSAE: ', grid_result3.best_score_)\n","    print('Best Params: ', grid_result3.best_params_)\n","    \n","    return clf.best_estimator_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M1Iid8zjFKOQ"},"outputs":[],"source":["# running 10 fold cross validation for evaluation of the input model and returning the mean of all 10 scores \n","def k_fold_score(model, X ,y):\n","    kf = KFold(n_splits = 5)\n","    rmse_list = []\n","    r2_list = []\n","    mae_list = []\n","    for train_index, test_index in kf.split(X, y):\n","        X_train,X_test = X.iloc[train_index],X.iloc[test_index]\n","        y_train,y_test = y.iloc[train_index],y.iloc[test_index]\n","\n","        X_train = pipeline.fit_transform(X_train)\n","        X_test = pipeline.transform(X_test)\n","        \n","        model.fit(X_train,y_train)\n","        y_predict = model.predict(X_test)\n","\n","        rmse = (np.sqrt(mean_squared_error(y_test, y_predict)))\n","        r2 = r2_score(y_test, y_predict)\n","        mae = mean_absolute_error(y_test,y_predict)\n","\n","        rmse_list.append(rmse)\n","        r2_list.append(r2)\n","        mae_list.append(mae)\n","\n","\n","    rmse_list = np.array(rmse_list)\n","    r2_list = np.array(r2_list)\n","    mae_list = np.array(mae_list)\n","\n","    print(\"--------------------------------------\")\n","    print('RMSE is {}'.format(rmse_list.mean()))\n","    print('R2 score is {}'.format(r2_list.mean()))\n","    print('MAE score is {}'.format(mae_list.mean()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hg-7rIP2FKOQ"},"outputs":[],"source":["# translating dataset as defined in the pipeline\n","X_train = pipeline.fit_transform(X_train)\n","X_test = pipeline.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kaTCiKbHFKOR"},"outputs":[],"source":["# seperating the data set to be used in grid search and cross validation\n","data_gs, data_cv, target_gs, target_cv = train_test_split(X, y, test_size=0.95, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"kzh8lSTjFKOR"},"source":["### LinearRegression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uk69AGusFKOO"},"outputs":[],"source":["# final evaluation and plotting hist for the difference between predicted and real labels\n","from matplotlib.ticker import PercentFormatter\n","def get_predict(model,X_train,y_train,X_test,y_test):\n","    print(\"\\nThe model performance for training set\")\n","    print(\"--------------------------------------\")\n","    y_predict = model.predict(X_train)\n","    rmse_r2_mae(model,y_train,y_predict)\n","    print(\"\\nThe model performance for testing set\")\n","    print(\"--------------------------------------\")\n","    y_predict = model.predict(X_test)\n","    rmse_r2_mae(model,y_test,y_predict)\n","    plt.figure(figsize=(5,5))\n","    diff = (y_test - y_predict)\n","    n,bins,rects= plt.hist(diff, bins = 25,weights=np.ones(len(diff)) / len(diff))\n","    plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n","    plt.grid()\n","    plt.xlim((-1,1))\n","    #rects = ax.patches   \n","    '''for rect in rects:\n","      height = rect.get_height()\n","      plt.text(rect.get_x() + rect.get_width() / 2, height+0.01, str(int(height//0.001)/10)+'%',\n","              ha='center', va='bottom')'''\n","    plt.xlabel('Prediction error', fontsize=18)\n","    plt.ylabel('Frequency', fontsize=18)\n","    plt.figure()\n","    count, bins_count = np.histogram(diff, bins=25)\n","    # finding the PDF of the histogram using count values\n","    pdf = count / sum(count)\n","      \n","    # using numpy np.cumsum to calculate the CDF\n","    # We can also find using the PDF values by looping and adding\n","    cdf = np.cumsum(pdf)\n","      \n","    # plotting PDF and CDF\n","    plt.plot(bins_count[1:], pdf, color=\"red\", label=\"PDF\")\n","    plt.plot(bins_count[1:], cdf, label=\"CDF\")\n","    plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aAadLzjDwj8E"},"outputs":[],"source":["# final evaluation and plotting hist for the difference between predicted and real labels\n","from matplotlib.ticker import PercentFormatter\n","def get_predict2(model,X_train,y_train,X_test,y_test):\n","    '''print(\"\\nThe model performance for training set\")\n","    print(\"--------------------------------------\")\n","    y_predict = model.predict(X_train)\n","    rmse_r2_mae(model,y_train,y_predict)\n","    print(\"\\nThe model performance for testing set\")\n","    print(\"--------------------------------------\")'''\n","    y_predict = model.predict(X_test)\n","    #rmse_r2_mae(model,y_test,y_predict)\n","    plt.figure(figsize=(5,5))\n","    diff = (y_test - y_predict)\n","    n,bins,rects= plt.hist(diff, bins = 12,weights=np.ones(len(diff)) / len(diff))\n","    plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n","    plt.grid()\n","    plt.xlim((-1,1))\n","    #rects = ax.patches   \n","    for rect in rects:\n","      height = rect.get_height()\n","      plt.text(rect.get_x() + rect.get_width() / 2, height+0.01, str(int(height//0.001)/10)+'%',\n","              ha='center', va='bottom')\n","    plt.xlabel('Prediction error', fontsize=18)\n","    plt.ylabel('Frequency', fontsize=18)"]},{"cell_type":"markdown","metadata":{"id":"9PezXp0zFKOR"},"source":["### Cross Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GjEz3KCNFKOR"},"outputs":[],"source":["lin_model = LinearRegression()\n","lin_model.fit(X_train, y_train)\n","get_predict(lin_model,X_train,y_train,X_test,y_test)"]},{"cell_type":"markdown","metadata":{"id":"mk346p1DFKOS"},"source":["### random Search"]},{"cell_type":"markdown","metadata":{"id":"-Gme9mdWFKOS"},"source":["**Elastic-Net Regression**\n","\n","Elastic-net is a linear regression model that combines the penalties of Lasso and Ridge."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jVJCDcd2FKOS"},"outputs":[],"source":["# indicating the potential parameters to be used in trial and error \n","params = {\n","    'alpha':[0.001, 0.01, 0.1, 1, 10, 100, 1000],       \n","    'l1_ratio':[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n","}\n","\n","en = ElasticNet()\n","\n","pipeline = ColumnTransformer([\n","        (\"numerical\", numerical_pipeline, numerical_columns),\n","        (\"categorical\", OneHotEncoder(handle_unknown = \"ignore\"), categorical_columns),\n","    ])\n","# calling random search for elastic net \n","en_model = get_model_random_search(en, params, data_gs, target_gs, pipeline)"]},{"cell_type":"markdown","metadata":{"id":"USlGsrqfFKOS"},"source":["### K Fold"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tLuVCmwZFKOT"},"outputs":[],"source":["k_fold_score(en_model,data_cv, target_cv) # on training data (80%) using 10_fold cross validation of elastic net algorithm"]},{"cell_type":"markdown","metadata":{"id":"jbYDjDI1FKOU"},"source":["## Support Vector Machine Regressor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XHtRzgqCFKOV"},"outputs":[],"source":["svr = SVR(kernel='rbf',C=100)\n","svr.fit(X_train, y_train)\n","get_predict(svr,X_train,y_train,X_test,y_test)"]},{"cell_type":"markdown","metadata":{"id":"bKfxxdTCFKOW"},"source":["### Random Search"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bchbqrOqFKOW"},"outputs":[],"source":["# doing the same thing as elastic net for SVR\n","params = {  'C': [0.1, 1, 10, 100, 1000],\n","            'epsilon': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n","            'gamma': [0.0001, 0.001, 0.005, 0.1, 1, 3, 5]\n","        }\n","\n","svr = SVR(kernel='rbf')\n","\n","pipeline = ColumnTransformer([\n","        (\"numerical\", numerical_pipeline, numerical_columns),\n","        (\"categorical\", OneHotEncoder(handle_unknown = \"ignore\"), categorical_columns),\n","    ])\n","\n","svr_rs_model = get_model_random_search(svr, params, data_gs, target_gs, pipeline)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Cg4h2wHFKOX"},"outputs":[],"source":["k_fold_score(svr_rs_model, data_cv, target_cv)"]},{"cell_type":"markdown","metadata":{"id":"CV43nkYj02y4"},"source":["# **Result:**\n","\n","# ***linear reg:***\n","\n","\n","*   The model performance for training set\n","    --------------------------------------\n","    RMSE is 1.8406440524613408\\\n","    R2 score is 0.8459335740915573\\\n","    MAE score is 1.37154352825972\n","\n","\n","\n","\n","*    The model performance for testing set\n","    --------------------------------------\n","    RMSE is 1.8031524314000584\\\n","    R2 score is 0.8442903378589373\\\n","    MAE score is 1.333618957614806\n","\n","#    ***Elastic net*** :\n","\n","*    Best R2:  0.8424886379654106\n","    \n","*    Best MAE:  1.3502965110395042\n","    \n","*    Best MSAE:  1.841129702786808\n","\n","*    Best Params:  alpha: 0.1, l1_ratio: 1\n","\n","# ***SVR***\n","\n","*   The model performance for training set\n","    --------------------------------------\n","    RMSE is 0.2488812643948367\\\n","    R2 score is 0.9971832208788407\\\n","    MAE score is 0.14058093534326982\n","\n","*    The model performance for testing set\n","    --------------------------------------\n","    RMSE is 0.30315675650110846\\\n","    R2 score is 0.9955986573274681\\\n","    MAE score is 0.16715031899685914\n","#    random search:\n","*   Best R2:  0.9934061443981413\n","*Best MAE:  0.2709478856261804\n","*Best MSAE:  0.3758950035569143\n","*Best Params:  C: 1000, 'epsilon': 0.05, 'gamma': 0.005\n","\n"]}],"metadata":{"colab":{"name":"training models + cdf- hist-r2-mae-msae.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}